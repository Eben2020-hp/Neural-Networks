{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1 align='center'> Neural Network from Scratch </h1>\r\n",
    "<h3 align='center'> Creating Batches and Layers </h3>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Why Batch? \r\n",
    "This will help perform more parallel operations. Because showing the model 1 sample at a time helps the best fit line fit faster.\r\n",
    "\r\n",
    "### What will happen if we fit all the Data at once?\r\n",
    "This can lead to over-fitting. This can hurt your Neural Network.  \r\n",
    "\r\n",
    "**The most common Batch Size is equal to 32.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dot product of a 1 Layer of Neurons"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "inputs = [[1, 2, 3, 2.5], \r\n",
    "          [2.0, 5.0, -1.0, 2.0], \r\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\r\n",
    "\r\n",
    "### We don't need to change anything in our Weights and Bias as they are uniquely associated with the neuron.\r\n",
    "weights = [[0.2, 0.8, -0.5, 1], \r\n",
    "           [0.5, -0.91, 0.26, -0.5], \r\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\r\n",
    "\r\n",
    "biases = [2, 3, 0.5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here the weights and inputs are the same shape. So they will give an error (shape error).\r\n",
    "- Using np.shape() we see that shape of Weights and Inputs are (3,4) --> It is a 3x4 matrix.\r\n",
    "\r\n",
    "> - Now for Matrix multiplication the number if Columns of the 1st Matrix should be equal to the number of Rows of the 2nd.\r\n",
    "> - For this we use the concept of transpose. This is simply switching the rows in a martix to the column.\r\n",
    "\r\n",
    "***For performing Transpose we will convert Weights to numpy array.***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "output1 = np.dot(inputs, np.array(weights).T) + biases      \r\n",
    "print(output1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dot product of a 2 Layer of Neurons"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "inputs = [[1, 2, 3, 2.5], \r\n",
    "          [2.0, 5.0, -1.0, 2.0], \r\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\r\n",
    "\r\n",
    "### Layer 1\r\n",
    "weights = [[0.2, 0.8, -0.5, 1], \r\n",
    "           [0.5, -0.91, 0.26, -0.5], \r\n",
    "           [-0.26, -0.27, 0.17, 0.87]]\r\n",
    "\r\n",
    "biases = [2, 3, 0.5]\r\n",
    "\r\n",
    "\r\n",
    "### Layer 2\r\n",
    "weights2 = [[0.1, -0.14, 0.5], \r\n",
    "           [-0.5, 0.12, -0.33], \r\n",
    "           [-0.44, 0.73, -0.13]]\r\n",
    "\r\n",
    "biases2 = [-1, 2, -0.5]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "layer1_output = np.dot(inputs, np.array(weights).T) + biases     \r\n",
    "print('This is Layer 1 output \\n',layer1_output)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This is Layer 1 output \n",
      " [[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**This Output becomes the inputs for Layer 2.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "layer2_output = np.dot(layer1_output, np.array(weights2).T) + biases2  \r\n",
    "print('This is Layer 2 output \\n',layer2_output)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "This is Layer 2 output \n",
      " [[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### **Rather than doing all this, we will convert these to objects.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "np.random.seed(0)       ## Setting a random seed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "## Input Data\r\n",
    "X = [[1, 2, 3, 2.5], \r\n",
    "          [2.0, 5.0, -1.0, 2.0], \r\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\r\n",
    "\r\n",
    "# Hidden Layers\r\n",
    "class Layer_Dense:\r\n",
    "    def __init__(self, n_inputs, n_neurons):\r\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)   ## For this we need to know the size of the inputs coming in and the size of the neurons in the hidden layer.\r\n",
    "        self.biases = np.zeros((1, n_neurons))\r\n",
    "    def forward(self, inputs):\r\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "- We will initialize weights to be in between [-1,1] and bias to be 0(Not always recommended). \r\n",
    "- This is so that the value (XW+b) is not too high.\r\n",
    "\r\n",
    "> ***np.random.randn --> generates Gaussian values.***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "layer1 = Layer_Dense(4,5)   ## (n_inputs= 4, n_neurons= 5)\r\n",
    "layer2 = Layer_Dense(5,2)   ## The output from layer1 should be the input."
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "layer1.forward(X)\r\n",
    "print(layer1.output)        ## This becomes the input for layer2."
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.10758131  1.03983522  0.24462411  0.31821498  0.18851053]\n",
      " [-0.08349796  0.70846411  0.00293357  0.44701525  0.36360538]\n",
      " [-0.50763245  0.55688422  0.07987797 -0.34889573  0.04553042]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "layer2.forward(layer1.output)\r\n",
    "print(layer2.output)        "
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[ 0.148296   -0.08397602]\n",
      " [ 0.14100315 -0.01340469]\n",
      " [ 0.20124979 -0.07290616]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "> We get a 3x2 matrix --> **3x4.4x5.5x2 = 3x2**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "a6c8cccf23fc189a51b8b2ae4ca3b98de763e12cce4f9033fe8d82721c91cecc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}